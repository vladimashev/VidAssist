# VidAssist: LLM-based Goal-Oriented Planning in Instructional Videos

Implementation of the paper:  
**"Propose, Assess, Search: Harnessing LLMs for Goal-Oriented Planning in Instructional Videos"**  
[arXiv:2409.20557](https://arxiv.org/abs/2409.20557)

---

## ğŸ“Œ Overview

**VidAssist** is a modular framework designed to perform goal-oriented reasoning in instructional videos using Large Language Models (LLMs).  
It supports zero-shot and few-shot planning and operates in three stages:

1. **Propose** â€“ Generate candidate actions using an LLM.
2. **Assess** â€“ Evaluate candidate actions using scoring functions.
3. **Search** â€“ Use breadth-first search to select optimal action sequences.

The framework is evaluated on standard datasets like **COIN** and **CrossTask**.

---

## ğŸ§  Key Features

- ğŸ¤– LLM-based semantic planning.
- ğŸ” Breadth-first search over plan proposals.
- ğŸ§ª Zero/few-shot performance without full supervision.
- ğŸ§© Modular design: you can plug in your own LLM or scoring functions.

---

## ğŸ“‚ Project Structure
